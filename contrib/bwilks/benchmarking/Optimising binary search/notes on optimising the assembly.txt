20/02/2022 (whilst investigating the slowdown)

turns out that there was a bug in the register allocator
where an instruction had two operands that were spilled to the stack
and needed to be reloaded. Previously it was using r0 for both, e.g.

	ldr r0, [sp #4]
	ldr r0, [sp, #8]
	sub r7, r0, r0

This is clearly wrong, weirdly though the algorithm still worked for the given input?
and gave the correct answer.

After the fix the assembly looked a bit like this:

	ldr r0, [sp, #4]
	ldr r1, [sp, #8]
	sub r7, r0, r1

Think this came from the mem2reg optimisations, looking at bb1 it was a bit like this (before mem2reg):

.bb1
	ldr r0, [sp #8]
	ldr r7, [r0]
	ldr r0, [sp, #4]
	ldr r8, [r0]
	cmp r7, r8
	....

Then after mem2reg was added it ended up looking like this:

	ldr r0, [sp, #8]
	ldr r0, [sp, #4]
	cmp r0, r0
	...

which is obviously wrong :(

HOW DID IT WORK


EDIT: Turns out that this was the cause of the SLOWDOWN!!!!

Fix is in ee817ed796cb59511438281fe17914f4613464c6

benchmarking given the fix to the above bug:

2022-02-20T16:43:20+00:00
Running build/binary_search
Run on (4 X 1500 MHz CPU s)
Load Average: 0.29, 0.15, 0.10
-------------------------------------------------------------
Benchmark                   Time             CPU   Iterations
-------------------------------------------------------------
BM_FUNCTION(Helix)       96.2 ns         96.2 ns      7198260
BM_FUNCTION(TCC)         97.9 ns         97.9 ns      7287709
BM_FUNCTION(Clang)       17.3 ns         17.3 ns     40355702
BM_FUNCTION(GCC)         43.4 ns         43.4 ns     16144287



.............................................................


Next thing to target is bb0, where it loads the array onto the
stack element by  element

Percent│       movw r7, #14
       │       movt r7, #0
       │       movw r6, #4
       │       movt r6, #0
       │       mul  r8, r7, r6
       │       add  r6, r4, r8
  1.25 │       mov  r7, r6
       │       movw r4, #2050       ; 0x802
       │       movt r4, #0
  4.46 │       str  r4, [r7]
       │       mov  r8, r5
       │       movw r7, #15
       │       movt r7, #0
       │       movw r6, #4
       │       movt r6, #0
       │       mul  r4, r7, r6
       │       add  r6, r8, r4
  1.38 │       mov  r7, r6
       │       movw r8, #20312      ; 0x4f58
       │       movt r8, #0
  5.84 │       str  r8, [r7]

lots of this ^, generally following the pattern


	movw r7, #14         ; Index
	movt r7, #0          ;
	movw r6, #4          ; Element Size
	movt r6, #0          ;
	mul  r8, r7, r6      ; Compute address (index * element size, 14 * 4)
	add  r6, r4, r8      ; Add address to array base to get element offset
	mov  r7, r6          ;
	movw r4, #2050       ; The element value itself 
	movt r4, #0          ;
	str  r4, [r7]        ; Store the element into the given address

to load one just one element!

Note that here the 14 * 4 calculation can be done at compile time.

Let's add this to the (generic) peephole optimiser.
	- Modify peephole optimiser so that it continually runs until no changes have been made


now gets code that looks like this for loading a single element

        movw r6, #56    ; Load precomputed offset (14 * 4)
        movt r6, #0     ;
        add r8, r7, r6  ; Add that offset to the array base (calculating the address)
        mov r4, r8      ;
        movw r6, #2050  ; The element value itself
        movt r6, #0     ;
        str r6, [r4]    ; Store the element into the given address

Improvements here are saving on the multiplication (which isn't the cheapest operation) (gets rid
of 3 instructions, a movw/movt pair and the mul)

Profiling after the above changes:

	2022-02-20T17:27:16+00:00
	Running ./binary_search
	Run on (4 X 1500 MHz CPU s)
	Load Average: 0.15, 0.13, 0.09
	-------------------------------------------------------------
	Benchmark                   Time             CPU   Iterations
	-------------------------------------------------------------
	BM_FUNCTION(Helix)       82.7 ns         82.7 ns      8456484
	BM_FUNCTION(TCC)         96.1 ns         96.1 ns      7286236
	BM_FUNCTION(Clang)       17.3 ns         17.3 ns     40359861
	BM_FUNCTION(GCC)         43.0 ns         43.0 ns     16278998


Seems to save ~10ns






